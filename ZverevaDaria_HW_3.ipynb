{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1\n",
    "\n",
    "### Bias-variance-noise decomposition\n",
    "\n",
    "$E_{x,y}E_{X^l}\\left[\\left(y - a_{X^l}(x)\\right)^2\\right] = E_{x,y}E_{X^l}\\left[\\left(y - E_{X^l}a_{X^l}(x) + E_{X^l}a_{X^l}(x) - a_{X^l} \\right)^2\\right] = E_{X^l}a_{X^l}\\left[\\left(y - E_{X^l}a_{X^l}(x)\\right)\\right] + 2\\cdot E_{x,y}E_{X^l}\\left[\\left(y - E_{X^l}a_{X^l}(x)\\right)\\cdot\\left(E_{X^l}a_{X^l}(x)- a_{X^l}(x)\\right)\\right] + E_{x,y}E_{X^l}\\left[\\left(E_{x^l}a_{X^l}(x) - a_{X^l}(x)\\right)^2\\right]$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем 2-ое слагаемое:\n",
    "\n",
    "$2\\cdot E_{x,y}E_{X^l}\\left[\\left(y - E_{X^l}a_{X^l}(x)\\right)\\cdot\\left(E_{X^l}a_{X^l}(x)- a_{X^l}(x)\\right)\\right] = $ $ = 2\\cdot \\left(E_{x,y}E_{X^l}\\left[y\\cdot E_{X^l}a_{X^l}(x) - E_{x,y}(E_{X^l}a_{X^l}(x))^2\\right] - E_{x,y}\\left[(y\\cdot E_{X^l}a_{X^l}(x) + E_{x,y}(E_{X^l}a_{X^l}(x))^2\\right] \\right) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда:\n",
    "\n",
    "$E_{x,y}E_{X^l}\\left[\\left(y - a_{X^l}(x)\\right)^2\\right] = E_{x,y}E_{X^l}\\left[\\left(y - E_{X^l}a_{X^l}(x)\\right)^2 \\right] + Var = E_{x,y}E_{X^l}\\left[\\left(y - E(y|x) + E(y|x) + a_{X^l}(x)\\right)^2\\right] + Var = $ $ = E_{x,y}\\left[\\left(y - E(y|x)\\right)^2\\right] + E_{x,y}\\left[\\left(E(y|x) - E_{X^l}a_{X^l}(x)\\right)^2\\right] + 2 \\cdot E_{x,y}\\left[(y - E(y|x))(E(y|x) - E_{X^l}a_{X^l}(x))\\right] + Var$\n",
    "\n",
    "Теперь воспользуемся независимостью и $E(E(y|x) - E_{X^l}a_{X^l}(x)) = 0$\n",
    "\n",
    "$2\\cdot E_{x,y}\\left[ \\left( y - E(y|x) \\right) \\cdot\\left(E(y|x) - E_{X^l}a_{X^l}(x)\\right)\\right] = 2 \\cdot E_{x,y}(y-E(y|x))\\cdot E_{x,y}(E(y|x)-E_{X^l}a_{x^l}(x)) = 0$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть в конечном итоге мы получаем:\n",
    "\n",
    "$E_{x,y}E_{X^l}(y - a_{X^l}(x))^2 = Noise + Bias^2 + Var$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2.2\n",
    "\n",
    "Выясните как соотносится смещение и разброс для композиции алгоритмов с теми же параметрами для базовых алгоритмов, если композиция строится с помощью бэггинга:\n",
    "\n",
    "$$a(x) = \\frac{1}{M} \\sum_{m=1}^M a_m(x)$$\n",
    "\n",
    "Решение:\n",
    "\n",
    "#### Смещение\n",
    "\n",
    "$E_{x,y}\\left[ \\left( E_{X^l}\\left[ \\frac{1}{M} \\sum_{m=1}^M a_m(x) \\right] - E[y|x] \\right)^2 \\right] = E_{x,y}\\left[ \\left( \\frac{1}{N} \\sum_{m=1}^M E_{X^l}\\left[a_{X^l}(x) - E[y|x]\\right] \\right)^2 \\right] = E_{x,y} \\left[ \\left( E_{X^l}\\left[a_{X^l}(x) - E[y|x]\\right] \\right)^2  \\right] = E_{x,y} \\left[ \\left( E_{X^l}\\left[a_{X^l}(x)\\right] - E[y|x] \\right)^2  \\right]$\n",
    "\n",
    "Что совпадает со смещением базового алгоритма.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Разброс\n",
    "\n",
    "$E_{x,y} \\left[ E_{X^l} \\left[ \\left(  \\frac{1}{M} \\sum_{m=1}^M a_m(x) - E_{X^l} \\left[ \\frac{1}{M} \\sum_{m=1}^M a_m(x) \\right] \\right)^2 \\right]  \\right] $\n",
    "\n",
    "Рассмотрим выражение под матожиданиями\n",
    "\n",
    "$ \\left(  \\frac{1}{M} \\sum_{m=1}^M a_m(x) - E_{X^l} \\left[ \\frac{1}{M} \\sum_{m=1}^M a_m(x) \\right] \\right)^2 = \\frac{1}{M^2} \\left( \\sum_{m=1}^{M}\\left[ a_{X^l}(x) - E_{X^l} \\left[ a_{X^l}(x) \\right] \\right] \\right)^2 =  \\frac{1}{M^2} \\sum_{m=1}^{M}\\left( \\left[ a_{X^l}(x) - E_{X^l} \\left[ a_{X^l}(x) \\right] \\right] \\right)^2 + \\frac{1}{M^2} \\sum_{m_1 \\not= m_2}^{M}\\left( \\left[ a_{X^l}(x) - E_{X^l} \\left[ a_{X^l}(x) \\right] \\right] \\right)\\left( \\left[ a_{X^l}(x) - E_{X^l} \\left[ a_{X^l}(x) \\right] \\right] \\right)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь возьмем матожидание\n",
    "\n",
    "$E_{x,y} \\left[ E_{X^l} \\left[ \\frac{1}{M^2} \\sum_{m=1}^{M}\\left( \\left[ a_{X^l}(x) - E_{X^l} \\left[ a_{X^l}(x) \\right] \\right] \\right)^2 + \\frac{1}{M^2} \\sum_{m_1 \\not= m_2}^{M}\\left( \\left[ a_{X^l}(x) - E_{X^l} \\left[ a_{X^l}(x) \\right] \\right] \\right)\\cdot \\left( \\left[ a_{X^l}(x) - E_{X^l} \\left[ a_{X^l}(x) \\right] \\right] \\right) \\right] \\right] = \n",
    "\\frac{1}{M^2} E_{x,y} \\left[ E_{X^l} \\left[  \\sum_{m=1}^{M}\\left( \\left[ a_{X^l}(x) - E_{X^l} \\left[ a_{X^l}(x) \\right] \\right] \\right)^2 \\right] \\right] + \\frac{1}{M^2} E_{x,y} \\left[ E_{X^l} \\left[ \\sum_{m_1 \\not= m_2}^{M}\\left( \\left[ a_{X^l}(x) - E_{X^l} \\left[ a_{X^l}(x) \\right] \\right] \\right)\\cdot \\left( \\left[ a_{X^l}(x) - E_{X^l} \\left[ a_{X^l}(x) \\right] \\right] \\right) \\right] \\right] =  \\frac{1}{M} E_{x,y} \\left[ E_{X^l} \\left[  \\left( \\left[ a_{X^l}(x) - E_{X^l} \\left[ a_{X^l}(x) \\right] \\right] \\right)^2 \\right] \\right] + \\frac{M(M-1)}{M^2} E_{x,y} \\left[ E_{X^l} \\left[ \\left( \\left[ a_{X^l}(x) - E_{X^l} \\left[ a_{X^l}(x) \\right] \\right] \\right)\\cdot \\left( \\left[ a_{X^l}(x) - E_{X^l} \\left[ a_{X^l}(x) \\right] \\right] \\right) \\right] \\right]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В получившейся сумме первое слагаемое - дисперсия базового алгоритма, делённая на количество алгоритмов в композиции.\n",
    "\n",
    "Втоорое - Ковариация между двумя базовыми алгоритмамы.\n",
    "\n",
    "То есть, если базовые алгоритмы некоррелированны, то дисперсия композиции в M раз меньше дисперсии одного алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3\n",
    "\n",
    "Есть $M$ о. р. с. в. с дисперсией $\\sigma^2$, любые две из которых имеют корреляцию $\\rho$. Показать, что дисперсия их среднего равна $\\rho \\sigma^2 + (1-\\rho) \\frac{\\sigma^2}{M}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Решение:\n",
    "\n",
    "$\\xi_1 \\ldots \\xi_M$ - н о р с в\n",
    "\n",
    "$D\\xi = \\sigma^2$\n",
    "\n",
    "Пусть $E \\xi = 0$. Тогда \n",
    "\n",
    "$D\\xi = E\\left[\\xi^2\\right]$\n",
    "\n",
    "$D\\left(\\frac{1}{M} \\sum_{m=1}^{M} \\xi_m\\right) = E \\left[ \\left(\\frac{1}{M} \\sum_{m=1}^{M} \\xi_m\\right)^2 \\right] - \\left(E \\left[ \\left(\\frac{1}{M} \\sum_{m=1}^{M} \\xi_m\\right) \\right]\\right)^2 = E \\left[ \\left(\\frac{1}{M} \\sum_{m=1}^{M} \\xi_m\\right)^2 \\right] = \\frac{1}{M^2} E \\left[ \\left( \\sum_{m=1}^{M} \\xi_m\\right)^2 \\right] $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{1}{M^2} E \\left[ \\left( \\sum_{m=1}^{M} \\xi_m\\right)^2 \\right] = \\frac{1}{M^2} E \\left[ \\sum_{m=1}^{M} \\xi_m^2 \\right] + \\frac{1}{M^2} E \\left[ \\sum_{m_1 \\not= m_2}^{M} \\xi_{m_1} \\cdot \\xi_{m_2} \\right] = \\frac{1}{M} \\sigma^2 + \\frac{M(M-1)}{M^2} \\rho \\sigma^2 = \\rho \\sigma^2 + (1-\\rho)\\frac{\\sigma^2}{M}$\n",
    "\n",
    "\n",
    "А так как прибавление константы не влияет на дисперсию, то мы для любой случайной величины получаем требуемое утрвеждение."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
